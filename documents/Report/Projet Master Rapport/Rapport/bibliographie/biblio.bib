@book{CleanCode,
  title={Clean code: a handbook of agile software craftsmanship},
  author={Martin, Robert C},
  year={2009},
  publisher={Pearson Education}
}

@misc{SyntaxDef, 
    title = {Syntaxe - Glossaire MDN : Définitions des Termes du web: MDN}, 
    journal = {MDN Web Docs}, 
    author = {MozDevNet},
    howpublished  = {\url{https://developer.mozilla.org/fr/docs/Glossary/Syntax}}
} 

@article{LanguageSyntax,
  title={An empirical investigation into programming language syntax},
  author={Stefik, Andreas and Siebert, Susanna},
  journal={ACM Transactions on Computing Education (TOCE)},
  volume={13},
  number={4},
  pages={1--40},
  year={2013},
  publisher={ACM New York, NY, USA}
}

@inproceedings{ChatBotOverview,
  title={An overview of chatbot technology},
  author={Adamopoulou, Eleni and Moussiades, Lefteris},
  booktitle={IFIP international conference on artificial intelligence applications and innovations},
  pages={373--383},
  year={2020},
  organization={Springer}
}

@article{chopra2013natural,
  title={Natural language processing},
  author={Chopra, Abhimanyu and Prashar, Abhinav and Sain, Chandresh},
  journal={International journal of technology enhancements and emerging engineering research},
  volume={1},
  number={4},
  pages={131--134},
  year={2013},
  publisher={Citeseer}
}

@article{nadkarni2011natural,
  title={Natural language processing: an introduction},
  author={Nadkarni, Prakash M and Ohno-Machado, Lucila and Chapman, Wendy W},
  journal={Journal of the American Medical Informatics Association},
  volume={18},
  number={5},
  pages={544--551},
  year={2011},
  publisher={BMJ Group BMA House, Tavistock Square, London, WC1H 9JR}
}

@article{raina2022natural,
  title={Natural language processing},
  author={Raina, Vineet and Krishnamurthy, Srinath and Raina, Vineet and Krishnamurthy, Srinath},
  journal={Building an Effective Data Science Practice: A Framework to Bootstrap and Manage a Successful Data Science Practice},
  pages={63--73},
  year={2022},
  publisher={Springer}
}


@article{liddy2001natural,
  title={Natural language processing},
  author={Liddy, Elizabeth D},
  year={2001}
}

@article{labelle2001trente,
  title={Trente ans de psycholinguistique},
  author={Labelle, Marie},
  journal={Revue qu{\'e}b{\'e}coise de linguistique},
  volume={30},
  number={1},
  pages={155--176},
  year={2001},
  publisher={{\'E}rudit}
}

@misc{deeplearning.ai, 
    title={Natural language processing (NLP) - A complete guide}, 
    howpublished = {\url{https://www.deeplearning.ai/resources/natural-language-processing/}}, 
    journal={(NLP) [A Complete Guide]}, 
    author={deeplearning.ai}
} 

@misc{von2015business,
  title={Business Process Model and Notation-BPMN.},
  howpublished = {\url{http://www.omg.org/news/whitepapers/Business_Process_Model_and_Notation.pdf}},
  author={von Rosing, Mark and White, Stephen and Cummins, Fred and de Man, Henk},
  year={2015}
}

@misc{NeoLedge_2019, 
    title = {Définition: Processus Métier},
    howpublished={\url{https://www.neoledge.com/fr/a-propos/glossaire/definition-processus-metier/}}, 
    author={NeoLedge},
    journal={NeoLedge}, 
    year={2019}, 
    month={May}
}

@article{grossi2007introduction,
  title={Introduction to artificial neural networks},
  author={Grossi, Enzo and Buscema, Massimo},
  journal={European journal of gastroenterology \& hepatology},
  volume={19},
  number={12},
  pages={1046--1054},
  year={2007},
  publisher={LWW}
}

@article{dindouveapprentissage,
  title={Apprentissage moteur et plasticit{\'e} c{\'e}r{\'e}brale chez le patient h{\'e}mipar{\'e}tique apr{\`e}s AVC: L’apprentissage bimanuel est-il am{\'e}lior{\'e} par dual-tDCS, compar{\'e} {\`a} une stimulation placebo?},
  author={Dindouve, Am{\'e}lie and Vandermeeren, Yves}
}

@misc{EponaMind, 
    title={Imagerie vétérinaire – Metron Software},
    howpublished={\url{https://www.eponamind.com/fr/neural-networks-deep-learning/}}, 
    journal={EponaMind}
} 

@misc{Gandhi_2018, 
    title={Support Vector Machine - introduction to machine learning algorithms}, 
    howpublished={\url{https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47}}, 
    journal={Medium}, 
    publisher={Towards Data Science}, 
    author={Gandhi, Rohith}, 
    year={2018}, 
    month={Jul}
} 

@misc{Post_2018,
    title={SVM - Data Analytics},
    howpublished={\url{https://dataanalyticspost.com/Lexique/svm/}}, 
    journal={Data Analytics Post}, 
    year={2018}, 
    month={Dec}
} 

@misc{Lutkevich_2022, 
    title={What is a parser? definition, types and examples}, 
    howpublished={\url{https://www.techtarget.com/searchapparchitecture/definition/parser}}, 
    journal={App Architecture}, 
    publisher={TechTarget}, 
    author={Lutkevich, Ben}, 
    year={2022}, 
    month={Jul}
} 

@misc{Induraj_2023, 
    title={What are sparse features and dense features?}, 
    howpublished={\url{https://induraj2020.medium.com/what-are-sparse-features-and-dense-features-8d1746a77035}}, 
    journal={Medium}, 
    publisher={Medium}, 
    author={Induraj}, 
    year={2023}, 
    month={Feb}
} 

@misc{Barua_2021, 
    title={Contextual v/s non-contextual word embedding models for Hindi named entity recognition}, 
    howpublished={\url{https://medium.com/@barua.aindriya/contextual-v-s-non-contextual-word-embedding-models-for-hindi-named-entity-recognition-1e6a34fc63d6}}, 
    journal={Medium}, 
    publisher={Medium}, 
    author={Aindriya Barua}, 
    year={2021}, 
    month={Dec}
} 

@misc{Imeshadilshani_2023, 
    title={Words as vectors - sparse vectors vs. dense vectors}, 
    howpublished={\url{https://medium.com/@imeshadilshani212/words-as-vectors-sparse-vectors-vs-dense-vectors-18e2084ad312}}, 
    journal={Medium}, 
    publisher={Medium}, 
    author={Imeshadilshani}, 
    year={2023}, 
    month={Dec}
} 

@misc{Aghammadzada_2020, 
    title={Chatbots: Intent Recognition Dataset}, 
    howpublished={\url{https://www.kaggle.com/datasets/elvinagammed/chatbots-intent-recognition-dataset}}, 
    journal={Kaggle}, 
    author={Aghammadzada, Elvin}, 
    year={2020}, 
    month={Oct}
} 

@misc{Satter_2022, 
    title={Classification des intentions : Qu’est-ce que c’est et comment l’utiliser avec des exemples}, howpublished={\url{https://www.questionpro.com/blog/fr/intention-classification/}}, 
    journal={QuestionPro}, 
    author={Satter, Sanjida}, 
    year={2022}, 
    month={Sep}
} 

@misc{Vojtko_2023, 
    title={Bert Model – bidirectional encoder representations from Transformers}, 
    howpublished={\url{https://quantpedia.com/bert-model-bidirectional-encoder-representations-from-transformers/}}, 
    journal={QuantPedia}, 
    author={Vojtko, Radovan}, 
    year={2023}, 
    month={Jul}
} 

@misc{Hashemi_Pour_Lutkevich_2024, 
    title={What is the bert language model?: Definition from techtarget.com}, 
    howpublished={\url{https://www.techtarget.com/searchenterpriseai/definition/BERT-language-model}}, 
    journal={Enterprise AI}, 
    publisher={TechTarget}, 
    author={Hashemi-Pour, Cameron and Lutkevich, Ben}, 
    year={2024}, 
    month={Feb}
} 

@misc{Horev_2018, 
    title={Bert explained: State of the art language model for NLP},
    howpublished={\url{https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270}}, 
    journal={Medium}, 
    publisher={Towards Data Science}, 
    author={Horev, Rani}, 
    year={2018}, 
    month={Nov}
} 

@misc{Hugging_encodeur_decodeur,
title={Les modèles de séquence-à-séquence - Hugging Face},
howpublished={\url{https://huggingface.co/learn/nlp-course/fr/chapter1/7}}, 
journal={Les modèles de séquence-à-séquence - Hugging Face}
} 

@misc{Hugging_decodeur,
title={Les modèles basés sur le décodeur - Hugging Face},
howpublished={\url{https://huggingface.co/learn/nlp-course/fr/chapter1/6}}, 
journal={Les modèles de séquence-à-séquence - Hugging Face}
} 

@misc{Hugging_encodeur,
title={Les modèles basés sur le encodeur - Hugging Face},
howpublished={\url{https://huggingface.co/learn/nlp-course/fr/chapter1/5}}, 
journal={Les modèles de séquence-à-séquence - Hugging Face}
} 

@misc{learning_rate,
title = {Comparative Analysis of Recurrent Neural Network Architectures for Reservoir Inflow Forecasting},
howpublished={\url{https://www.researchgate.net/figure/Changes-in-the-loss-function-vs-the-epoch-by-the-learning-rate-40_fig2_341609757}}, 
journal={Changes in the loss function vs. the epoch by the learning rate [40]. | download scientific diagram}
} 